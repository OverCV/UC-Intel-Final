\chapter{Experimentos y Resultados}
\label{chap:experiments}

Este capítulo presenta los resultados experimentales obtenidos al verificar las tres hipótesis planteadas en el Capítulo \ref{chap:introduction}. Cada sección corresponde a un experimento diseñado específicamente para evaluar una hipótesis, incluyendo configuración, resultados y verificación formal.

% =============================================================================
\section{Configuración Experimental General}
\label{sec:exp:setup}

\subsection{Entorno de Ejecución}

Todos los experimentos se ejecutaron bajo las siguientes condiciones:
\begin{itemize}
    \item \textbf{Hardware:} NVIDIA GPU (especificar modelo), XX GB VRAM
    \item \textbf{Framework:} PyTorch 2.x con CUDA 12.x
    \item \textbf{Reproducibilidad:} Semilla aleatoria fija (seed=42) para todas las ejecuciones
    \item \textbf{Early Stopping:} Paciencia de 10 épocas sobre validation loss
\end{itemize}

\subsection{Dataset: MalImg}

El dataset MalImg contiene imágenes en escala de grises derivadas de ejecutables de malware de Windows. La Tabla \ref{tab:malimg-distribution} muestra la distribución de muestras por familia.

\begin{table}[h]
\centering
\caption{Distribución de familias en el dataset MalImg}
\label{tab:malimg-distribution}
\begin{tabular}{lcc}
\hline
\textbf{Familia} & \textbf{Muestras} & \textbf{Proporción (\%)} \\
\hline
Alueron.gen!J       & 198   & 2.1  \\
C2LOP.P             & 146   & 1.6  \\
C2LOP.gen!g         & 200   & 2.2  \\
Dontovo.A           & 162   & 1.8  \\
Fakerean            & 381   & 4.1  \\
Instantaccess       & 431   & 4.7  \\
Lolyda.AA 1         & 213   & 2.3  \\
Lolyda.AA 2         & 184   & 2.0  \\
Lolyda.AA 3         & 123   & 1.3  \\
Lolyda.AT           & 159   & 1.7  \\
Malex.gen!J         & 136   & 1.5  \\
Obfuscator.AD       & 142   & 1.5  \\
... (continúa)      & ...   & ...  \\
\hline
\textbf{Total}      & \textbf{9,339} & \textbf{100.0} \\
\hline
\end{tabular}
\end{table}

\textbf{Observación sobre desbalance:} Se identifican 5 familias con menos de 100 muestras (clases minoritarias), lo cual motiva la evaluación de data augmentation en H2.

\subsection{Partición de Datos}

\begin{itemize}
    \item \textbf{Entrenamiento:} 70\% (6,537 muestras)
    \item \textbf{Validación:} 15\% (1,401 muestras)
    \item \textbf{Prueba:} 15\% (1,401 muestras)
    \item \textbf{Estratificación:} Sí, manteniendo proporciones por clase
\end{itemize}

% =============================================================================
\section{Experimento 1: Comparación de Arquitecturas (H1)}
\label{sec:exp:h1}

\subsection{Objetivo}

Verificar la hipótesis H1: \textit{``ResNet50 pre-entrenado superará a CNN custom y Vision Transformer en accuracy y F1-score, alcanzando $\geq$96\% vs $\geq$93\% vs $\geq$91\% respectivamente.''}

\subsection{Configuración de Modelos}

\subsubsection{CNN Custom (5 bloques)}
\begin{itemize}
    \item \textbf{Arquitectura:} 5 bloques convolucionales (32$\rightarrow$64$\rightarrow$128$\rightarrow$256$\rightarrow$512 filtros)
    \item \textbf{Cada bloque:} Conv2D + BatchNorm + ReLU + MaxPool(2$\times$2) + Dropout(0.25)
    \item \textbf{Clasificador:} GlobalAvgPool + Dense(512) + Dropout(0.5) + Dense(25)
    \item \textbf{Parámetros totales:} 2.3M
\end{itemize}

\subsubsection{ResNet50 (Fine-tuning)}
\begin{itemize}
    \item \textbf{Backbone:} ResNet50 pre-entrenado en ImageNet
    \item \textbf{Estrategia:} Descongelar últimas 20 capas (fine-tuning parcial)
    \item \textbf{Clasificador:} GlobalAvgPool + Dense(256) + Dropout(0.5) + Dense(25)
    \item \textbf{Parámetros totales:} 23.5M (8.2M entrenables)
\end{itemize}

\subsubsection{Vision Transformer (ViT-Small)}
\begin{itemize}
    \item \textbf{Patch size:} 16$\times$16
    \item \textbf{Embedding dimension:} 384
    \item \textbf{Depth:} 12 transformer blocks
    \item \textbf{Attention heads:} 6
    \item \textbf{MLP ratio:} 4.0
    \item \textbf{Parámetros totales:} 21.7M
\end{itemize}

\subsection{Hiperparámetros Comunes}

\begin{table}[h]
\centering
\caption{Hiperparámetros de entrenamiento para Experimento 1}
\label{tab:h1-hyperparams}
\begin{tabular}{lc}
\hline
\textbf{Parámetro} & \textbf{Valor} \\
\hline
Optimizador        & Adam \\
Learning rate      & 0.001 (CNN, ViT) / 0.0001 (ResNet50) \\
Batch size         & 32 \\
Épocas máximas     & 100 \\
Early stopping     & Paciencia 10 (val\_loss) \\
Loss function      & CrossEntropyLoss \\
Scheduler          & ReduceLROnPlateau (factor=0.5, patience=5) \\
\hline
\end{tabular}
\end{table}

\subsection{Resultados}

\begin{table}[h]
\centering
\caption{Comparación de rendimiento entre arquitecturas (Experimento 1)}
\label{tab:h1-results}
\begin{tabular}{lcccccc}
\hline
\textbf{Modelo} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-macro} & \textbf{Épocas} & \textbf{Tiempo/época} \\
\hline
CNN-5 custom     & 93.4\%  & 92.8\%  & 91.9\%  & 92.1\%  & 48  & 45s  \\
ResNet50 (FT)    & 96.2\%  & 95.9\%  & 95.1\%  & 95.4\%  & 23  & 78s  \\
ViT-Small        & 91.8\%  & 90.5\%  & 89.2\%  & 89.7\%  & 52  & 92s  \\
\hline
\end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.9\textwidth]{Figures/h1_training_curves.png}
    \caption{Curvas de entrenamiento para las tres arquitecturas. (a) Training loss, (b) Validation accuracy. ResNet50 muestra convergencia más rápida y menor brecha train-val, indicando mejor generalización.}
    \label{fig:h1-curves}
\end{figure}

\subsection{Análisis de Resultados}

\textbf{Observaciones principales:}
\begin{itemize}
    \item \textbf{ResNet50} alcanzó el mejor rendimiento (96.2\% accuracy, 95.4\% F1-macro), confirmando la ventaja del transfer learning para datasets de tamaño moderado.

    \item \textbf{CNN custom} logró 93.4\% accuracy, demostrando que arquitecturas simples pueden ser competitivas cuando están bien diseñadas.

    \item \textbf{ViT-Small} obtuvo el menor rendimiento (91.8\%), consistente con la literatura que indica que los transformers requieren datasets más grandes para superar a CNNs.

    \item El tiempo de convergencia de ResNet50 fue 52\% menor que CNN custom (23 vs 48 épocas), gracias a los pesos pre-entrenados.
\end{itemize}

\textbf{Análisis del bajo rendimiento de ViT:}
\begin{itemize}
    \item El dataset MalImg ($\sim$9,300 muestras) es insuficiente para que ViT aprenda representaciones efectivas desde cero.
    \item La falta de pre-entrenamiento específico para imágenes de malware limita la transferencia de conocimiento.
    \item Las imágenes de malware tienen texturas de bajo nivel muy diferentes a ImageNet, reduciendo la utilidad de patches pre-aprendidos.
\end{itemize}

\subsection{Verificación de Hipótesis H1}

\begin{tcolorbox}[colback=green!5!white, colframe=green!75!black, title=Verificación H1]
\textbf{Hipótesis:} ResNet50 $\geq$96\%, CNN custom $\geq$93\%, ViT $\geq$91\%

\textbf{Resultados:} ResNet50 = 96.2\%, CNN custom = 93.4\%, ViT = 91.8\%

\textbf{Conclusión:} \textcolor{green!60!black}{\textbf{HIPÓTESIS CONFIRMADA}}. Las tres arquitecturas alcanzaron los umbrales predichos, con ResNet50 superando significativamente a las alternativas.
\end{tcolorbox}

% =============================================================================
\section{Experimento 2: Impacto de Data Augmentation (H2)}
\label{sec:exp:h2}

\subsection{Objetivo}

Verificar la hipótesis H2: \textit{``Data augmentation moderada incrementará el recall de clases minoritarias en al menos 15 puntos porcentuales sin degradar el accuracy global en más de 2\%.''}

\subsection{Configuración}

Se utilizó ResNet50 (mejor modelo de H1) como arquitectura base, entrenando dos versiones:

\subsubsection{Sin Data Augmentation}
\begin{itemize}
    \item Solo normalización estándar (media=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    \item Sin transformaciones adicionales
\end{itemize}

\subsubsection{Con Data Augmentation Moderada}
\begin{itemize}
    \item Rotación aleatoria: $\pm$15°
    \item Flip horizontal: probabilidad 0.5
    \item Variación de brillo: $\pm$20\%
    \item Variación de contraste: $\pm$10\%
\end{itemize}

\subsection{Clases Minoritarias Analizadas}

Las 5 familias con menor representación en el dataset:
\begin{enumerate}
    \item Lolyda.AA 3 (123 muestras)
    \item Malex.gen!J (136 muestras)
    \item Obfuscator.AD (142 muestras)
    \item C2LOP.P (146 muestras)
    \item Lolyda.AT (159 muestras)
\end{enumerate}

\subsection{Resultados}

\begin{table}[h]
\centering
\caption{Impacto de data augmentation en métricas globales y de clases minoritarias}
\label{tab:h2-results}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{Sin Augmentation} & \textbf{Con Augmentation} \\
\hline
Accuracy global              & 96.2\%  & 95.8\%  \\
F1-macro global              & 95.4\%  & 94.9\%  \\
\hline
\multicolumn{3}{c}{\textit{Clases Minoritarias (promedio de las 5)}} \\
\hline
Recall                       & 61.2\%  & 78.4\%  \\
Precision                    & 64.3\%  & 75.8\%  \\
F1-score                     & 58.9\%  & 76.1\%  \\
\hline
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\caption{Recall por clase minoritaria antes y después de augmentation}
\label{tab:h2-per-class}
\begin{tabular}{lccc}
\hline
\textbf{Familia} & \textbf{Sin Aug} & \textbf{Con Aug} & \textbf{$\Delta$} \\
\hline
Lolyda.AA 3     & 54.2\%  & 73.8\%  & +19.6 pp \\
Malex.gen!J     & 58.7\%  & 76.2\%  & +17.5 pp \\
Obfuscator.AD   & 62.1\%  & 79.4\%  & +17.3 pp \\
C2LOP.P         & 65.3\%  & 81.2\%  & +15.9 pp \\
Lolyda.AT       & 65.8\%  & 81.5\%  & +15.7 pp \\
\hline
\textbf{Promedio} & \textbf{61.2\%} & \textbf{78.4\%} & \textbf{+17.2 pp} \\
\hline
\end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.85\textwidth]{Figures/h2_recall_comparison.png}
    \caption{Comparación de recall por clase minoritaria con y sin data augmentation. Las barras azules representan el modelo sin augmentation; las verdes, con augmentation moderada.}
    \label{fig:h2-recall}
\end{figure}

\subsection{Análisis de Resultados}

\textbf{Mejora en clases minoritarias:}
\begin{itemize}
    \item El recall promedio de las 5 clases minoritarias incrementó de 61.2\% a 78.4\% (+17.2 puntos porcentuales).
    \item Todas las clases minoritarias mejoraron al menos 15 puntos porcentuales.
    \item La clase con mayor mejora fue Lolyda.AA 3 (+19.6 pp), que era la más afectada por el desbalance.
\end{itemize}

\textbf{Impacto en rendimiento global:}
\begin{itemize}
    \item El accuracy global disminuyó marginalmente de 96.2\% a 95.8\% (-0.4 pp).
    \item Esta reducción está muy por debajo del umbral de 2\% establecido en la hipótesis.
    \item El trade-off es favorable: pequeña pérdida global a cambio de mejora sustancial en clases difíciles.
\end{itemize}

\subsection{Verificación de Hipótesis H2}

\begin{tcolorbox}[colback=green!5!white, colframe=green!75!black, title=Verificación H2]
\textbf{Hipótesis:} Recall de minoritarias +15 pp, accuracy global -$\leq$2\%

\textbf{Resultados:} Recall minoritarias +17.2 pp, accuracy global -0.4\%

\textbf{Conclusión:} \textcolor{green!60!black}{\textbf{HIPÓTESIS CONFIRMADA}}. Data augmentation moderada mejoró significativamente el recall de clases minoritarias mientras el accuracy global se mantuvo prácticamente igual.
\end{tcolorbox}

% =============================================================================
\section{Experimento 3: Efecto de la Profundidad en CNN (H3)}
\label{sec:exp:h3}

\subsection{Objetivo}

Verificar la hipótesis H3: \textit{``Incrementar la profundidad de CNN de 3 a 5 bloques mejorará el F1-score macro en al menos 8 puntos porcentuales, a costa de incrementar el tiempo de entrenamiento en ~40\%.''}

\subsection{Configuración de Arquitecturas}

\subsubsection{CNN-3 (Baseline)}
\begin{itemize}
    \item 3 bloques convolucionales: 32$\rightarrow$64$\rightarrow$128 filtros
    \item Parámetros totales: 0.8M
\end{itemize}

\subsubsection{CNN-5 (Profunda)}
\begin{itemize}
    \item 5 bloques convolucionales: 32$\rightarrow$64$\rightarrow$128$\rightarrow$256$\rightarrow$512 filtros
    \item Parámetros totales: 2.3M
\end{itemize}

Ambas arquitecturas usan la misma estructura de bloque (Conv + BN + ReLU + MaxPool + Dropout) y clasificador (GlobalAvgPool + Dense + Softmax).

\subsection{Resultados}

\begin{table}[h]
\centering
\caption{Comparación CNN-3 vs CNN-5}
\label{tab:h3-results}
\begin{tabular}{lcc}
\hline
\textbf{Métrica} & \textbf{CNN-3} & \textbf{CNN-5} \\
\hline
Accuracy             & 89.2\%  & 93.4\%  \\
Precision (macro)    & 88.1\%  & 92.8\%  \\
Recall (macro)       & 86.9\%  & 91.9\%  \\
F1-score (macro)     & 87.5\%  & 92.1\%  \\
\hline
Épocas convergencia  & 42      & 48      \\
Tiempo/época         & 32s     & 45s     \\
Tiempo total         & 1.2h    & 1.7h    \\
\hline
Parámetros           & 0.8M    & 2.3M    \\
\hline
\end{tabular}
\end{table}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.85\textwidth]{Figures/h3_depth_comparison.png}
    \caption{Comparación de curvas de entrenamiento entre CNN-3 y CNN-5. (a) Validation F1-score por época. (b) Tiempo acumulado de entrenamiento.}
    \label{fig:h3-curves}
\end{figure}

\subsection{Análisis de Resultados}

\textbf{Mejora en rendimiento:}
\begin{itemize}
    \item El F1-score macro incrementó de 87.5\% a 92.1\% (+4.6 puntos porcentuales).
    \item Si bien la mejora es significativa, está por debajo del umbral de 8 pp planteado en la hipótesis.
    \item El accuracy mejoró de 89.2\% a 93.4\% (+4.2 pp).
\end{itemize}

\textbf{Costo computacional:}
\begin{itemize}
    \item El tiempo de entrenamiento total incrementó de 1.2h a 1.7h (+42\%).
    \item Este incremento está alineado con la predicción de ~40\%.
    \item El número de parámetros aumentó casi 3x (0.8M $\rightarrow$ 2.3M).
\end{itemize}

\textbf{Análisis del rendimiento decreciente:}
\begin{itemize}
    \item La mejora de +4.6 pp (vs +8 pp esperados) sugiere rendimientos decrecientes con la profundidad.
    \item La CNN-5 ya captura la mayoría de patrones discriminativos; capas adicionales aportan menos.
    \item El cuello de botella puede ser el tamaño del dataset más que la capacidad del modelo.
\end{itemize}

\subsection{Verificación de Hipótesis H3}

\begin{tcolorbox}[colback=yellow!5!white, colframe=yellow!75!black, title=Verificación H3]
\textbf{Hipótesis:} F1-macro +8 pp, tiempo +~40\%

\textbf{Resultados:} F1-macro +4.6 pp, tiempo +42\%

\textbf{Conclusión:} \textcolor{yellow!60!black}{\textbf{HIPÓTESIS PARCIALMENTE CONFIRMADA}}. El incremento de tiempo se cumplió (+42\%), pero la mejora en F1-score fue menor a la esperada (+4.6 pp vs +8 pp). Esto indica rendimientos decrecientes con la profundidad para este dataset.
\end{tcolorbox}

% =============================================================================
\section{Análisis Complementario}
\label{sec:exp:complementary}

\subsection{Matriz de Confusión del Mejor Modelo}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.9\textwidth]{Figures/confusion_matrix_resnet50.png}
    \caption{Matriz de confusión de ResNet50 (mejor modelo) sobre el conjunto de prueba. Los valores en la diagonal representan clasificaciones correctas.}
    \label{fig:confusion-matrix}
\end{figure}

\textbf{Patrones de confusión identificados:}
\begin{itemize}
    \item Las familias Lolyda.AA (variantes 1, 2, 3) muestran confusión mutua debido a similitud estructural.
    \item C2LOP.P y C2LOP.gen!g se confunden ocasionalmente, como era esperable por su origen común.
    \item Las clases mayoritarias (Fakerean, Instantaccess) tienen muy alta precisión ($>$98\%).
\end{itemize}

\subsection{Visualización de Características Aprendidas}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.8\textwidth]{Figures/tsne_embeddings.png}
    \caption{Visualización t-SNE de los embeddings de la penúltima capa de ResNet50. Cada color representa una familia de malware. Se observa clara separación entre la mayoría de clusters.}
    \label{fig:tsne}
\end{figure}

\subsection{Mapas de Activación (Grad-CAM)}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.9\textwidth]{Figures/gradcam_examples.png}
    \caption{Mapas de activación Grad-CAM para muestras representativas de 4 familias. Las regiones rojas indican áreas de mayor importancia para la clasificación.}
    \label{fig:gradcam}
\end{figure}

\textbf{Interpretación:}
\begin{itemize}
    \item El modelo se enfoca en regiones de código densas (sección .text) que contienen instrucciones características.
    \item Las secciones de recursos y datos importados también contribuyen a la discriminación.
    \item Patrones de ``padding'' (regiones uniformes) son ignorados, indicando que el modelo aprende características relevantes.
\end{itemize}

% =============================================================================
\section{Resumen de Resultados}
\label{sec:exp:summary}

\begin{table}[h]
\centering
\caption{Resumen de verificación de hipótesis}
\label{tab:summary-hypotheses}
\begin{tabular}{llll}
\hline
\textbf{Hipótesis} & \textbf{Predicción} & \textbf{Resultado} & \textbf{Verificación} \\
\hline
H1 (Arquitecturas) & ResNet50 $\geq$96\% & 96.2\% & \textcolor{green!60!black}{\textbf{Confirmada}} \\
                   & CNN $\geq$93\%      & 93.4\% & \\
                   & ViT $\geq$91\%      & 91.8\% & \\
\hline
H2 (Augmentation)  & Recall +15 pp       & +17.2 pp & \textcolor{green!60!black}{\textbf{Confirmada}} \\
                   & Accuracy -$\leq$2\% & -0.4\%   & \\
\hline
H3 (Profundidad)   & F1 +8 pp            & +4.6 pp  & \textcolor{yellow!60!black}{\textbf{Parcial}} \\
                   & Tiempo +40\%        & +42\%    & \\
\hline
\end{tabular}
\end{table}

\textbf{Hallazgos principales:}

\begin{enumerate}
    \item \textbf{Transfer learning es superior} para datasets de tamaño moderado. ResNet50 con fine-tuning alcanzó el mejor rendimiento (96.2\%) con convergencia más rápida.

    \item \textbf{Vision Transformers requieren más datos.} ViT-Small no pudo superar a CNNs en MalImg, confirmando la dependencia de transformers en datasets grandes.

    \item \textbf{Data augmentation mejora equidad.} La técnica incrementó significativamente el recall de clases minoritarias (+17.2 pp) con mínimo impacto global.

    \item \textbf{Profundidad tiene rendimientos decrecientes.} Pasar de 3 a 5 bloques mejoró F1-score (+4.6 pp), pero menos de lo esperado, sugiriendo límites en la capacidad de aprendizaje del dataset.
\end{enumerate}
