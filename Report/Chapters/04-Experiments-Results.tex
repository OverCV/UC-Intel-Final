\chapter{Experimentos y Resultados}
\label{chap:experiments}

Este capítulo presenta los resultados experimentales obtenidos al verificar las tres hipótesis planteadas en el Capítulo \ref{chap:introduction}. Cada sección corresponde a un experimento diseñado específicamente para evaluar una hipótesis, incluyendo configuración, resultados y verificación formal.

% =============================================================================
\section{Configuración Experimental General}
\label{sec:exp:setup}

\subsection{Entorno de Ejecución}

Todos los experimentos se ejecutaron bajo las siguientes condiciones:
\begin{itemize}
    \item \textbf{Hardware:} NVIDIA GPU (especificar modelo), XX GB VRAM
    \item \textbf{Framework:} PyTorch 2.x con CUDA 12.x
    \item \textbf{Reproducibilidad:} Semilla aleatoria fija (seed=42) para todas las ejecuciones
    \item \textbf{Early Stopping:} Paciencia de 10 épocas sobre validation loss
\end{itemize}

\subsection{Dataset: MalImg}

El dataset MalImg contiene imágenes en escala de grises derivadas de ejecutables de malware de Windows. La Tabla \ref{tab:malimg-distribution} muestra la distribución de muestras por familia.

\begin{table}[h]
\centering
\caption{Distribución de familias en el dataset MalImg}
\label{tab:malimg-distribution}
\begin{tabular}{lcc}
\hline
\textbf{Familia} & \textbf{Muestras} & \textbf{Proporción (\%)} \\
\hline
Alueron.gen!J       & 198   & 2.1  \\
C2LOP.P             & 146   & 1.6  \\
C2LOP.gen!g         & 200   & 2.2  \\
Dontovo.A           & 162   & 1.8  \\
Fakerean            & 381   & 4.1  \\
Instantaccess       & 431   & 4.7  \\
Lolyda.AA 1         & 213   & 2.3  \\
Lolyda.AA 2         & 184   & 2.0  \\
Lolyda.AA 3         & 123   & 1.3  \\
Lolyda.AT           & 159   & 1.7  \\
Malex.gen!J         & 136   & 1.5  \\
Obfuscator.AD       & 142   & 1.5  \\
... (continúa)      & ...   & ...  \\
\hline
\textbf{Total}      & \textbf{9,339} & \textbf{100.0} \\
\hline
\end{tabular}
\end{table}

\textbf{Observación sobre desbalance:} Se identifican 5 familias con menos de 100 muestras (clases minoritarias), lo cual motiva la evaluación de data augmentation en H2.

\subsection{Partición de Datos}

\begin{itemize}
    \item \textbf{Entrenamiento:} 70\% (6,537 muestras)
    \item \textbf{Validación:} 15\% (1,401 muestras)
    \item \textbf{Prueba:} 15\% (1,401 muestras)
    \item \textbf{Estratificación:} Sí, manteniendo proporciones por clase
\end{itemize}

% =============================================================================
\section{Experimento 1: Comparación de Arquitecturas (H1)}
\label{sec:exp:h1}

\subsection{Objetivo}

Verificar la hipótesis H1: \textit{``ResNet50 pre-entrenado en ImageNet con fine-tuning superará tanto a una CNN custom como a un Vision Transformer en accuracy y F1-score macro.''}

\subsection{Configuración de Modelos}

Se evaluaron cuatro arquitecturas: un baseline convencional, una CNN profunda de 5 bloques, ResNet50 con fine-tuning, y Vision Transformer.

\subsubsection{Conventional CNN (Baseline)}
\begin{itemize}
    \item \textbf{Arquitectura:} 2 bloques convolucionales (configuración estándar del curso)
    \item \textbf{Estructura:} Conv2D + MaxPool + Conv2D + MaxPool + Flatten + Dense
    \item \textbf{Propósito:} Establecer línea base de comparación
\end{itemize}

\subsubsection{VGG-Mini-H1 (5 bloques)}
\begin{itemize}
    \item \textbf{Arquitectura:} 5 bloques convolucionales (32$\rightarrow$64$\rightarrow$128$\rightarrow$256$\rightarrow$512 filtros)
    \item \textbf{Cada bloque:} Conv2D + BatchNorm + ReLU + MaxPool(2$\times$2)
    \item \textbf{Clasificador:} GlobalAvgPool + Dropout(0.5) + Dense(256) + Dropout(0.3) + Output
\end{itemize}

\subsubsection{ResNet50 (Fine-tuning)}
\begin{itemize}
    \item \textbf{Backbone:} ResNet50 pre-entrenado en ImageNet
    \item \textbf{Estrategia:} Partial fine-tuning (20-30 últimas capas descongeladas)
    \item \textbf{Clasificador:} Dropout(0.5) + Dense(512) + Output
\end{itemize}

\subsubsection{Vision Transformer (ViT-Small)}
\begin{itemize}
    \item \textbf{Patch size:} 16$\times$16
    \item \textbf{Embedding dimension:} 384
    \item \textbf{Depth:} 12 transformer blocks
    \item \textbf{Attention heads:} 6
    \item \textbf{MLP ratio:} 4.0
    \item \textbf{Dropout:} 0.1
\end{itemize}

% --- Archivos modulares ---
\input{Chapters/Experiments/h1-tables}

\input{Chapters/Experiments/h1-figures}

\input{Chapters/Experiments/h1-analysis}

\input{Chapters/Experiments/h1-verification}

% =============================================================================
\section{Experimento 2: Impacto de Data Augmentation (H2)}
\label{sec:exp:h2}

\subsection{Objetivo}

Verificar la hipótesis H2: \textit{``Data augmentation moderada mejorará significativamente el recall de las familias de malware minoritarias, sin degradar sustancialmente el accuracy global del modelo.''}

\subsection{Configuración}

Se utilizó el mejor modelo de H1 como arquitectura base, entrenando dos versiones: una sin augmentation y otra con augmentation moderada.

% --- Archivos modulares ---
\input{Chapters/Experiments/h2-tables}

\input{Chapters/Experiments/h2-figures}

\input{Chapters/Experiments/h2-analysis}

\input{Chapters/Experiments/h2-verification}

% =============================================================================
\section{Experimento 3: Efecto de la Profundidad en CNN (H3)}
\label{sec:exp:h3}

\subsection{Objetivo}

Verificar la hipótesis H3: \textit{``Incrementar la profundidad de una CNN custom mejorará el rendimiento del modelo, pero con rendimientos decrecientes y mayor costo computacional.''}

\subsection{Configuración de Arquitecturas}

Se compararon dos arquitecturas CNN con diferente profundidad, manteniendo la misma estructura de bloque (Conv + BN + ReLU + MaxPool) y clasificador.

% --- Archivos modulares ---
\input{Chapters/Experiments/h3-tables}

\input{Chapters/Experiments/h3-figures}

\input{Chapters/Experiments/h3-analysis}

\input{Chapters/Experiments/h3-verification}

% =============================================================================
\section{Análisis Complementario}
\label{sec:exp:complementary}

\subsection{Matriz de Confusión del Mejor Modelo}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.9\textwidth]{Figures/confusion_matrix_resnet50.png}
    \caption{Matriz de confusión de ResNet50 (mejor modelo) sobre el conjunto de prueba. Los valores en la diagonal representan clasificaciones correctas.}
    \label{fig:confusion-matrix}
\end{figure}

\textbf{Patrones de confusión identificados:}
\begin{itemize}
    \item Las familias Lolyda.AA (variantes 1, 2, 3) muestran confusión mutua debido a similitud estructural.
    \item C2LOP.P y C2LOP.gen!g se confunden ocasionalmente, como era esperable por su origen común.
    \item Las clases mayoritarias (Fakerean, Instantaccess) tienen muy alta precisión ($>$98\%).
\end{itemize}

\subsection{Visualización de Características Aprendidas}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.8\textwidth]{Figures/tsne_embeddings.png}
    \caption{Visualización t-SNE de los embeddings de la penúltima capa de ResNet50. Cada color representa una familia de malware. Se observa clara separación entre la mayoría de clusters.}
    \label{fig:tsne}
\end{figure}

\subsection{Mapas de Activación (Grad-CAM)}

\begin{figure}[h]
    \centering
    % \includegraphics[width=0.9\textwidth]{Figures/gradcam_examples.png}
    \caption{Mapas de activación Grad-CAM para muestras representativas de 4 familias. Las regiones rojas indican áreas de mayor importancia para la clasificación.}
    \label{fig:gradcam}
\end{figure}

\textbf{Interpretación:}
\begin{itemize}
    \item El modelo se enfoca en regiones de código densas (sección .text) que contienen instrucciones características.
    \item Las secciones de recursos y datos importados también contribuyen a la discriminación.
    \item Patrones de ``padding'' (regiones uniformes) son ignorados, indicando que el modelo aprende características relevantes.
\end{itemize}

% =============================================================================
\section{Resumen de Resultados}
\label{sec:exp:summary}

\begin{table}[h]
\centering
\caption{Resumen de verificación de hipótesis}
\label{tab:summary-hypotheses}
\begin{tabular}{lp{5cm}l}
\hline
\textbf{Hipótesis} & \textbf{Resultado Principal} & \textbf{Verificación} \\
\hline
H1 (Arquitecturas) & ResNet50 (96.30\%) superó a ViT (74.92\%) y CNN custom (61.30\%) & \textcolor{green!60!black}{\textbf{Confirmada}} \\
\hline
H2 (Augmentation)  & TODO: Completar con resultados & \textcolor{gray}{\textbf{TODO}} \\
\hline
H3 (Profundidad)   & TODO: Completar con resultados & \textcolor{gray}{\textbf{TODO}} \\
\hline
\end{tabular}
\end{table}

\textbf{Hallazgos principales:}

\begin{enumerate}
    \item \textbf{Transfer learning es superior} para datasets de tamaño moderado. ResNet50 con fine-tuning alcanzó el mejor rendimiento (96.30\%) con convergencia más rápida.

    \item \textbf{Vision Transformers requieren más datos.} ViT-Small (74.92\%) no pudo superar a ResNet50, confirmando la dependencia de transformers en datasets grandes.

    \item \textbf{Arquitecturas profundas sin skip connections fallan.} La CNN de 5 bloques (61.30\%) fue superada incluso por el baseline simple (72.39\%), evidenciando problemas de optimización.

    \item \textbf{TODO: Hallazgos de H2 y H3} (completar cuando se ejecuten los experimentos).
\end{enumerate}
